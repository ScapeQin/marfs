#!/bin/bash -e

# Fuse isn't intended to support parallel writes for a given writer, but
# many writers may write at the same time.

# Q: Can they get a better aggregate BW than an individual task?

# A: Yes.  I get ~200 MB/s for a single writer, and this has gotten
#    as high as ~600 MB/s.

# ISSUES:
#
# (1) marfs truncate takes considerable time, so we delete all the files
#     ahead of time, to avoid adding the cost of truncate to the
#     timeing-section.
#
# (2) If repo.chunksize is smaller than the per-task write-size, then the
#     writes will include the overhead of closing one object and opening a
#     new one, when fuse is creating Multi.  (The per-task write includes
#     ~2k of recovery-info, per object.)



# constants
M=$((1024 * 1024))
G=$((1024 * 1024 * 1024))

N_TASKS=8
BSIZE=$((256 * M))
COUNT=2


# total MB moved by all tasks
MB_TOT=$(( (N_TASKS * BSIZE * COUNT) / M ))

MB_EACH=$(( (BSIZE * COUNT) / M ))


# launch parallel jobs in the background
# wait for all jobs to complete, before returning
function do_tasks() {
    for i in `seq 1 $N_TASKS`; do
        FILE=/marfs/jti/parallel.`printf "%02d" $i`
        dd if=/dev/zero of=$FILE bs=$BSIZE count=$COUNT &
    done
    wait
}



# delete old versions of all files, so we don't measure the cost of
# truncating an existing file
for i in `seq 1 $N_TASKS`; do
    FILE=/marfs/jti/parallel.`printf "%02d" $i`
    echo "deleting $FILE"
    rm -f $FILE
done


# measure elapsed times for the parallel writes to all complete.
# NOTE: 'time' is a real POS.
echo "$N_TASKS parallel writers, writing $MB_EACH MB each (through fuse-mount)"
TIME=` (time do_tasks) 2>&1 | awk '/real/ {print $2}' `

echo "timing: $TIME"



# extract the number of seconds
SEC=`echo $TIME \
    | sed -re 's/^([0-9]+)m([0-9.]+)s/(60 * \1) + \2/' \
    | bc -q`

echo "total sec: $SEC"


# compute bandwidth
BW=`echo "$MB_TOT/$SEC" | bc -q`

echo "performance: $MB_TOT MB, $SEC sec = $BW MB/s"
